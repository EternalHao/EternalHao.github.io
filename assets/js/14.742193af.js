(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{160:function(t,e,n){"use strict";n.r(e);var a=n(0),o=Object(a.a)({},(function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("blockquote",[n("p",[t._v("这块也是面试被问烂的,什么C")])]),t._v(" "),n("ol",[n("li",[t._v("java.util.concurrent.atomic")]),t._v(" "),n("li",[t._v("ConcurrentHashMap")]),t._v(" "),n("li",[t._v("阻塞队列及特点")])]),t._v(" "),n("h3",{attrs:{id:"阻塞队列"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#阻塞队列"}},[t._v("#")]),t._v(" 阻塞队列")]),t._v(" "),n("blockquote",[n("p",[t._v("这个队列和我们日常使用到队列不同,它添加了阻塞的概念,阻塞的概念分为两种,\n阻塞添加 - 在队列添加的过程中,如果队列的元素已经满了,在后续添加元素的线程就会被阻塞,待到队列不满时,继续唤醒线程继续添加\n阻塞删除 - 在队列为空的时候,删除队列元素的线程会被阻塞,直到队列不为空在执行删除操作")])]),t._v(" "),n("ol",[n("li",[t._v("ArrayBlockingQueue")])]),t._v(" "),n("blockquote",[n("p",[t._v("是一个用数组实现的有界队列,按照先进先出的原则进行排序,ArrayBlockingQueue内部的阻塞队列是通过重入锁ReenterLock和Condition条件队列实现的,通过数组对象items来存储所有的数据,通过两个监视器notNull和NotEmpty实现阻塞,然后通过两个索引实现队列操作.")])]),t._v(" "),n("blockquote",[n("p",[t._v("入队列:\nput:  间接调用offer实现\noffer: 在开始加锁,判断队列是否已经满,没有满的情况下,加入队列,释放锁\nadd: 在开始加锁,判断队列是否满,如果已经吗满,运用notFull.await()阻塞当前线程,使线程进入等待队列,直到唤醒为止(队列可以添加元素)")])]),t._v(" "),n("blockquote",[n("p",[t._v("出队列:\npoll: 该方法获取并移除此队列的头元素，若队列为空，则返回 null,加锁,出队列,解锁,notFull.signal();\nremove:\n方法的删除过程相对复杂些，因为该方法并不是直接从队列头部删除元素。首先线程先获取锁，再一步判断队列count>0,这点是保证并发情况下删除操作安全执行。接着获取下一个要添加源的索引putIndex以及takeIndex索引 ，作为后续循环的结束判断，因为只要putIndex与takeIndex不相等就说明队列没有结束。然后通过while循环找到要删除的元素索引，执行removeAt(i)方法删除，在removeAt(i)方法中实际上做了两件事，一是首先判断队列头部元素是否为删除元素，如果是直接删除，并唤醒添加线程，二是如果要删除的元素并不是队列头元素，那么执行循环操作，从要删除元素的索引removeIndex之后的元素都往前移动一个位置，那么要删除的元素就被removeIndex之后的元素替换，从而也就完成了删除操作\ntake: 有就删除没有就阻塞，注意这个阻塞是可以中断的,如果队列没有数据那么就加入notEmpty条件队列等待,在队列put元素后会唤醒")])]),t._v(" "),n("blockquote",[n("p",[t._v("总结一下, 在添加元素的时候,如果队列已经满 则调用 notFull.await()阻塞线程, 在队列中元素被取走时,会执行     notFull.signal() 唤醒添加线程,在删除元素的时候,如果队列已空,则调用 notEmpty.await()阻塞删除线程,在队列元素添加后,添加线程会 notEmpty.signal() 唤醒删除线程,这是一个典型的生产者和消费者模型")])]),t._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[t._v("LinkedBlockingQueue")])]),t._v(" "),n("blockquote",[n("p",[t._v("从字面上来看,这是一个由列表实现的有届阻塞队列,但它的大小默认是 Integer.MAX_VALUE,LinkedBlockingQueue时建议手动传值，为其提供我们所需的大小，避免队列过大造成机器负载或者内存爆满等情况")])]),t._v(" "),n("blockquote",[n("p",[t._v("LinkedBlockingQueue是一个基于链表的阻塞队列，其内部维持一个基于链表的数据队列,有两个锁,一个takeLock,一个putLock,一个锁关联一个监视器,takeLock关联notEmpty,putLock关联 notFull,添加和删除操作并不是互斥操作，可以同时进行，这样也就可以大大提高吞吐量")])]),t._v(" "),n("p",[t._v("实现类式上面的额")]),t._v(" "),n("h3",{attrs:{id:"分段锁-concurrenthashmap"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#分段锁-concurrenthashmap"}},[t._v("#")]),t._v(" 分段锁 - ConcurrentHashMap")]),t._v(" "),n("blockquote",[n("p",[t._v("说到ConcurrentHashMap,我们不得不提一下HashMap,我们日常经常使用,但是他有个缺点就是不是线程安全的,在多线程的情况下可能会出现环状链表,形成死循环,导致CPU爆掉,为了解决这个问题的,我们想到了HashTable,但是HashTable虽然是安全的,但是效率很慢,他是通过给整个表加锁来实现同步的,在多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化,在竞争激烈的并发场景中性能就会非常差,后来就有了我们的HashMap安全版而且效率也不错--同步版的HashMap")])]),t._v(" "),n("p",[n("img",{attrs:{src:"https://images2015.cnblogs.com/blog/1024555/201705/1024555-20170514174100832-1891630860.png",alt:""}}),t._v('\nConcurrentHashMap采用了非常精妙的"分段锁"策略,主干是个Segment数组,首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问')]),t._v(" "),n("p",[t._v("ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。")]),t._v(" "),n("p",[t._v("HashMap ：先说HashMap，HashMap是线程不安全的，在并发环境下，可能会形成环状链表（扩容时可能造成，具体原因自行百度google或查看源码分析），导致get操作时，cpu空转，所以，在并发环境中使用HashMap是非常危险的")])])}),[],!1,null,null,null);e.default=o.exports}}]);